{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## TensorBoard"
      ],
      "metadata": {
        "id": "WXN6Q4bgXNGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "sHdK9JP8XLdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime"
      ],
      "metadata": {
        "id": "cA66tBz9Xaz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./logs/"
      ],
      "metadata": {
        "id": "3UU6XX0hXeU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 連接本機(fail)"
      ],
      "metadata": {
        "id": "0i-T0uSqUg90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-colab"
      ],
      "metadata": {
        "id": "eatvCtRaUEZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --execute index.ipynb"
      ],
      "metadata": {
        "id": "r4oIW3zlous1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "id": "iMTNv08TWQw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 前置作業"
      ],
      "metadata": {
        "id": "EY1OkPULv1me"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jShUzy75-L9y"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-gnn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sL8O51f0FIK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlEpI7zrSHhb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_gnn as tfgnn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "print(device_lib.list_local_devices())"
      ],
      "metadata": {
        "id": "SRm6xeW3ThJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwjaaCAXRYtj"
      },
      "outputs": [],
      "source": [
        "graph_tensor_spec = tfgnn.GraphTensorSpec.from_piece_specs(\n",
        "    context_spec=tfgnn.ContextSpec.from_field_specs(features_spec={\n",
        "                  'label': tf.TensorSpec(shape=(1,), dtype=tf.int32)\n",
        "    }),\n",
        "    node_sets_spec={\n",
        "        'atoms':\n",
        "            tfgnn.NodeSetSpec.from_field_specs(\n",
        "                features_spec={\n",
        "                    tfgnn.HIDDEN_STATE:\n",
        "                        tf.TensorSpec((None, 7), tf.float32)\n",
        "                },\n",
        "                sizes_spec=tf.TensorSpec((1,), tf.int32))\n",
        "    },\n",
        "    edge_sets_spec={\n",
        "        'bonds':\n",
        "          tfgnn.EdgeSetSpec.from_field_specs(\n",
        "            features_spec={\n",
        "                    tfgnn.HIDDEN_STATE:\n",
        "                        tf.TensorSpec((None, 4), tf.float32)\n",
        "                },\n",
        "                sizes_spec=tf.TensorSpec((1,), tf.int32),\n",
        "                adjacency_spec=tfgnn.AdjacencySpec.from_incident_node_sets(\n",
        "                    'atoms', 'atoms'))\n",
        "    })\n",
        "\n",
        "\n",
        "def decode_fn(record_bytes):\n",
        "  graph = tfgnn.parse_single_example(\n",
        "      graph_tensor_spec, record_bytes, validate=True)\n",
        "\n",
        "  # extract label from context and remove from input graph\n",
        "  print(graph)\n",
        "  context_features = graph.context.get_features_dict()\n",
        "  print(context_features)\n",
        "  label = context_features.pop('label')\n",
        "  print(context_features)\n",
        "  print(label)\n",
        "  new_graph = graph.replace_features(context=context_features)\n",
        "  print(new_graph.node_sets['atoms']['hidden_state'])\n",
        "  for _i in new_graph.node_sets['atoms']['hidden_state']:\n",
        "    print(_i)\n",
        "  return new_graph, label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load training data (for cross-validation)"
      ],
      "metadata": {
        "id": "s4Y-xzLZFfS4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4VykVm_qty3"
      },
      "outputs": [],
      "source": [
        "train_ds=[]\n",
        "val_ds=[]\n",
        "\n",
        "for itr in range(1,11):\n",
        "    train_path = '/content/drive/MyDrive/forth_dataset/10_folds_CV/train/train_smiles_'+str(itr)+'.tfrecord'\n",
        "    val_path = '/content/drive/MyDrive/forth_dataset/10_folds_CV/val/val_smiles_'+str(itr)+'.tfrecord'\n",
        "    train_ds.append(tf.data.TFRecordDataset([train_path]).map(decode_fn))\n",
        "    val_ds.append(tf.data.TFRecordDataset([val_path]).map(decode_fn))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load final training data"
      ],
      "metadata": {
        "id": "24lLoRbSFYvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_path='/content/drive/MyDrive/forth_dataset/all_train_smiles.tfrecord'\n",
        "final_ds=tf.data.TFRecordDataset([final_path]).map(decode_fn)"
      ],
      "metadata": {
        "id": "jqGIX9dcFTLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_ds.element_spec[1])"
      ],
      "metadata": {
        "id": "nYKVpxhMlM_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 蓋模型 (for cross-validation)"
      ],
      "metadata": {
        "id": "f2Z_1hdovrXb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOUCfdpp_w4v"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_ds_batched=[]\n",
        "val_ds_batched=[]\n",
        "\n",
        "for i in range(10):\n",
        "    train_ds_batched.append(train_ds[i].batch(batch_size=batch_size).repeat())\n",
        "    val_ds_batched.append(val_ds[i].batch(batch_size=batch_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7fhATRUexKh"
      },
      "outputs": [],
      "source": [
        "def _build_model(\n",
        "    graph_tensor_spec,\n",
        "    node_dim=16,\n",
        "    edge_dim=16,\n",
        "    message_dim=64,\n",
        "    next_state_dim=64,\n",
        "    num_classes=2,\n",
        "    num_message_passing=3,\n",
        "    l2_regularization=2e-3,\n",
        "    dropout_rate=0.2,\n",
        "):\n",
        "\n",
        "    input_graph = tf.keras.layers.Input(type_spec=graph_tensor_spec)\n",
        "    graph = input_graph.merge_batch_to_components()\n",
        "\n",
        "    def set_initial_node_state(node_set, *, node_set_name):\n",
        "        return tf.keras.layers.Dense(node_dim)(node_set[tfgnn.HIDDEN_STATE])\n",
        "\n",
        "    def set_initial_edge_state(edge_set, *, edge_set_name):\n",
        "        return tf.keras.layers.Dense(edge_dim)(edge_set[tfgnn.HIDDEN_STATE])\n",
        "\n",
        "    graph = tfgnn.keras.layers.MapFeatures(\n",
        "        node_sets_fn=set_initial_node_state, edge_sets_fn=set_initial_edge_state)(\n",
        "            graph)\n",
        "\n",
        "    def dense(units, activation=\"relu\"):\n",
        "        \"\"\"A Dense layer with regularization (L2 and Dropout).\"\"\"\n",
        "        regularizer = tf.keras.regularizers.l2(l2_regularization)\n",
        "        return tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(\n",
        "                units,\n",
        "                activation=activation,\n",
        "                kernel_regularizer=regularizer,\n",
        "                bias_regularizer=regularizer),\n",
        "            tf.keras.layers.Dropout(dropout_rate)\n",
        "        ])\n",
        "\n",
        "    for i in range(num_message_passing):\n",
        "        graph = tfgnn.keras.layers.GraphUpdate(\n",
        "            node_sets={\n",
        "                \"atoms\": tfgnn.keras.layers.NodeSetUpdate(\n",
        "                    {\"bonds\": tfgnn.keras.layers .SimpleConv(\n",
        "                        sender_edge_feature=tfgnn.HIDDEN_STATE,\n",
        "                        message_fn=dense(message_dim),\n",
        "                        reduce_type=\"sum\",\n",
        "                        receiver_tag=tfgnn.TARGET)},\n",
        "                    tfgnn.keras.layers.NextStateFromConcat(dense(next_state_dim)))}\n",
        "\n",
        "        )(graph)\n",
        "\n",
        "    readout_features = tfgnn.keras.layers.Pool(tfgnn.CONTEXT, \"mean\", node_set_name=\"atoms\")(graph)\n",
        "    logits = tf.keras.layers.Dense(1)(readout_features)\n",
        "\n",
        "    return tf.keras.Model(inputs=[input_graph], outputs=[logits])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./logs/"
      ],
      "metadata": {
        "id": "9_CJqs9jiPKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMotwUlM8U6s"
      },
      "outputs": [],
      "source": [
        "history={}\n",
        "\n",
        "model_input_graph_spec, label_spec = train_ds[0].element_spec\n",
        "del label_spec\n",
        "\n",
        "for i in range(1,11):\n",
        "\n",
        "    log_dir = \"logs/fit_\"+str(i)+\"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "    model = _build_model(model_input_graph_spec)\n",
        "\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    metrics = [tf.keras.metrics.BinaryAccuracy(threshold=0.),\n",
        "           tf.keras.metrics.BinaryCrossentropy(from_logits=True)\n",
        "           ]\n",
        "\n",
        "    model.compile(tf.keras.optimizers.Adam(), loss=loss, metrics=metrics)\n",
        "\n",
        "    model.summary()\n",
        "    history[str(i)]=model.fit(train_ds_batched[i-1],steps_per_epoch=8,epochs=250,validation_data=val_ds_batched[i-1], callbacks=[tensorboard_callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/fit_9"
      ],
      "metadata": {
        "id": "tJLfk8-UYBDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title=['loss', 'binary_accuracy', 'binary_crossentropy', 'val_loss', 'val_binary_accuracy', 'val_binary_crossentropy', 'recall', 'val_recall', 'precision', 'val_precision']\n",
        "train_loss=[]\n",
        "train_acc=[]\n",
        "train_bce=[]\n",
        "val_loss=[]\n",
        "val_acc=[]\n",
        "val_bce=[]\n",
        "\n",
        "for itr in range(1,11):\n",
        "    for k, hist in history[str(itr)].history.items():\n",
        "        if(k==title[0]):\n",
        "            train_loss.append(hist)\n",
        "        elif(k==title[1]):\n",
        "            train_acc.append(hist)\n",
        "        elif(k==title[2]):\n",
        "            train_bce.append(hist)\n",
        "        elif(k==title[3]):\n",
        "            val_loss.append(hist)\n",
        "        elif(k==title[4]):\n",
        "            val_acc.append(hist)\n",
        "        elif(k==title[5]):\n",
        "            val_bce.append(hist)\n",
        "\n",
        "train_loss=np.mean(train_loss, 0)\n",
        "train_acc=np.mean(train_acc, 0)\n",
        "train_bce=np.mean(train_bce, 0)\n",
        "val_loss=np.mean(val_loss, 0)\n",
        "val_acc=np.mean(val_acc, 0)\n",
        "val_bce=np.mean(val_bce, 0)"
      ],
      "metadata": {
        "id": "VvtdeNCF16xK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_acc[-1])"
      ],
      "metadata": {
        "id": "j-6x4GRbC1t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss, label='train')\n",
        "plt.plot(val_loss, label='validation')\n",
        "plt.legend()\n",
        "plt.title('loss')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_acc, label='train')\n",
        "plt.plot(val_acc, label='validation')\n",
        "plt.legend()\n",
        "plt.title('accracy')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_bce, label='train')\n",
        "plt.plot(val_bce, label='validation')\n",
        "plt.legend()\n",
        "plt.title('binary cross-entropy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YDXs1ova7gQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 蓋模型 (final)"
      ],
      "metadata": {
        "id": "emXekUy-GpnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "final_ds_batched=final_ds.batch(batch_size=batch_size).repeat()"
      ],
      "metadata": {
        "id": "csbcFWTTGox1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _build_model(\n",
        "    graph_tensor_spec,\n",
        "    node_dim=16,\n",
        "    edge_dim=16,\n",
        "    message_dim=64,\n",
        "    next_state_dim=64,\n",
        "    num_classes=2,\n",
        "    num_message_passing=3,\n",
        "    l2_regularization=2e-3,\n",
        "    dropout_rate=0.2,\n",
        "):\n",
        "\n",
        "    input_graph = tf.keras.layers.Input(type_spec=graph_tensor_spec)\n",
        "    graph = input_graph.merge_batch_to_components()\n",
        "\n",
        "    def set_initial_node_state(node_set, *, node_set_name):\n",
        "        return tf.keras.layers.Dense(node_dim)(node_set[tfgnn.HIDDEN_STATE])\n",
        "\n",
        "    def set_initial_edge_state(edge_set, *, edge_set_name):\n",
        "        return tf.keras.layers.Dense(edge_dim)(edge_set[tfgnn.HIDDEN_STATE])\n",
        "\n",
        "    graph = tfgnn.keras.layers.MapFeatures(\n",
        "        node_sets_fn=set_initial_node_state, edge_sets_fn=set_initial_edge_state)(\n",
        "            graph)\n",
        "\n",
        "    def dense(units, activation=\"tanh\"):\n",
        "        \"\"\"A Dense layer with regularization (L2 and Dropout).\"\"\"\n",
        "        regularizer = tf.keras.regularizers.l2(l2_regularization)\n",
        "        return tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(\n",
        "                units,\n",
        "                activation=activation,\n",
        "                kernel_regularizer=regularizer,\n",
        "                bias_regularizer=regularizer),\n",
        "            tf.keras.layers.Dropout(dropout_rate)\n",
        "        ])\n",
        "\n",
        "    for i in range(num_message_passing):\n",
        "        graph = tfgnn.keras.layers.GraphUpdate(\n",
        "            node_sets={\n",
        "                \"atoms\": tfgnn.keras.layers.NodeSetUpdate(\n",
        "                    {\"bonds\": tfgnn.keras.layers .SimpleConv(\n",
        "                        sender_edge_feature=tfgnn.HIDDEN_STATE,\n",
        "                        message_fn=dense(message_dim),\n",
        "                        reduce_type=\"sum\",\n",
        "                        receiver_tag=tfgnn.TARGET)},\n",
        "                    tfgnn.keras.layers.NextStateFromConcat(dense(next_state_dim)))}\n",
        "\n",
        "        )(graph)\n",
        "\n",
        "    readout_features = tfgnn.keras.layers.Pool(tfgnn.CONTEXT, \"mean\", node_set_name=\"atoms\")(graph)\n",
        "    logits = tf.keras.layers.Dense(1)(readout_features)\n",
        "\n",
        "    return tf.keras.Model(inputs=[input_graph], outputs=[logits])"
      ],
      "metadata": {
        "id": "sGvEVdRzHBqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_input_graph_spec, label_spec = final_ds.element_spec\n",
        "del label_spec\n",
        "model=_build_model(model_input_graph_spec)"
      ],
      "metadata": {
        "id": "sLDOVIQ-HLQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./logs/"
      ],
      "metadata": {
        "id": "Ajj3dE4EHKdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "metadata": {
        "id": "0i-MILG9Heiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metrics = [tf.keras.metrics.BinaryAccuracy(threshold=0.),\n",
        "           tf.keras.metrics.BinaryCrossentropy(from_logits=True),]"
      ],
      "metadata": {
        "id": "HsP8RksbHuuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(tf.keras.optimizers.Adam(), loss=loss, metrics=metrics)"
      ],
      "metadata": {
        "id": "5fkUelqEHxww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "cLNBPgmRH0DC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=False, show_layer_names=False, rankdir='LR')"
      ],
      "metadata": {
        "id": "XrfYi_YkEwQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(final_ds_batched, steps_per_epoch=9,epochs=250,callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "id": "Oo8nz_UTH1Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "metadata": {
        "id": "MloVK-VKIFwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, hist in history.history.items():\n",
        "    plt.title(k)\n",
        "    plt.plot(hist)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "G0Yd2evDIRIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 預測"
      ],
      "metadata": {
        "id": "6BR44mMx8AUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################Prediction of target################################"
      ],
      "metadata": {
        "id": "u5-j0wTsCldM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_path = '/content/drive/MyDrive/fifth_dataset/fda_fixed_1.tfrecord'\n",
        "predict_file = pd.read_csv('/content/drive/MyDrive/fifth_dataset/fda_fixed_predicted.csv')\n",
        "predict_ds = tf.data.TFRecordDataset([predict_path]).map(decode_fn)\n",
        "predict_ds_batched = predict_ds.batch(batch_size=1)\n",
        "print(predict_ds)"
      ],
      "metadata": {
        "id": "0dEi84xjSHE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(predict_ds_batched)"
      ],
      "metadata": {
        "id": "dQrlyHPX-JSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)"
      ],
      "metadata": {
        "id": "ddNlCe4_ikUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + math.exp(-x))"
      ],
      "metadata": {
        "id": "oDD7P3NxjABX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### use sigmoid ###\n",
        "pre_res=[]\n",
        "ans=[]\n",
        "rank=[]\n",
        "distn=[0,0,0,0,0,0,0,0,0,0]\n",
        "for idx,p in zip(range(len(predict_file)),predictions):\n",
        "    fix = round(sigmoid(p), 4)\n",
        "    pre_res.append(fix)\n",
        "    rank.append(fix)\n",
        "    rank.sort()\n",
        "    if (fix >= 0.9):\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[9]+=1\n",
        "    elif(fix>=0.8):\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[8]+=1\n",
        "    elif(fix>=0.7):\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[7]+=1\n",
        "    elif(fix>=0.6):\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[6]+=1\n",
        "    elif(fix>=0.5):\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[5]+=1\n",
        "    elif(fix>=0.4):\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[4]+=1\n",
        "    elif(fix>=0.3):\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[3]+=1\n",
        "    elif(fix>=0.2):\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[2]+=1\n",
        "    elif(fix>=0.1):\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[1]+=1\n",
        "    else:\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[0]+=1"
      ],
      "metadata": {
        "id": "lpN3q1R_jG7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### use tanh ###\n",
        "pre_res=[]\n",
        "ans=[]\n",
        "rank=[]\n",
        "distn=[0,0,0,0,0,0,0,0,0,0]\n",
        "for idx,p in zip(range(len(predict_file)),predictions):\n",
        "    fix = round(math.tanh(p)/2+0.5,4)\n",
        "    pre_res.append(fix)\n",
        "    if (fix >= 0.9):\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[9]+=1\n",
        "    elif(fix>=0.8):\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[8]+=1\n",
        "    elif(fix>=0.7):\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[7]+=1\n",
        "    elif(fix>=0.6):\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[6]+=1\n",
        "    elif(fix>=0.5):\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[5]+=1\n",
        "    elif(fix>=0.4):\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[4]+=1\n",
        "    elif(fix>=0.3):\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[3]+=1\n",
        "    elif(fix>=0.2):\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[2]+=1\n",
        "    elif(fix>=0.1):\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[1]+=1\n",
        "    else:\n",
        "        ans.append([predict_file.iloc[idx].values[0], fix])\n",
        "        distn[0]+=1\n"
      ],
      "metadata": {
        "id": "4X2tRf_D7yKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in ans:\n",
        "    print(i)\n",
        "print(len(ans))"
      ],
      "metadata": {
        "id": "WR9zBR9WRHMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rank.reverse()"
      ],
      "metadata": {
        "id": "MeN-ncDRW50T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(35):\n",
        "    print(rank[i])"
      ],
      "metadata": {
        "id": "aKq1iPTWWssu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(distn)"
      ],
      "metadata": {
        "id": "SMrSdUXZKnE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Write\n",
        "predict_file['SMILES']=pre_res\n",
        "predict_file.to_csv(\"/content/drive/MyDrive/third_dataset/fda_fixed_from_gnn.csv\",index=False)"
      ],
      "metadata": {
        "id": "_6WmxC8VNur_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 其他測試"
      ],
      "metadata": {
        "id": "zHJQjconTm5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################Prediction of next part's inputs############################"
      ],
      "metadata": {
        "id": "YOTT0mvnNXRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_train_path = '/content/drive/MyDrive/experiment_result/all_train_smiles.tfrecord'\n",
        "predict_train_ds = tf.data.TFRecordDataset([predict_train_path]).map(decode_fn)\n",
        "predict_train_ds_batched = predict_train_ds.batch(batch_size=1)"
      ],
      "metadata": {
        "id": "fQygHkKnB_Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_train = model.predict(predict_train_ds_batched)\n",
        "pre_train_res = []\n",
        "for p in predictions_train:\n",
        "    pre_train_res.append(round(math.tanh(p)/2+0.5,4))"
      ],
      "metadata": {
        "id": "65mHZcIwC4j4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_csv=pd.read_csv(\"/content/drive/MyDrive/dataset/train_filtered.csv\")\n",
        "predict_csv['SMILES']=pre_train_res\n",
        "predict_csv.to_csv(\"/content/drive/MyDrive/dataset/train_filtered.csv\",index=False)"
      ],
      "metadata": {
        "id": "_TG7fXUSJ5Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################################"
      ],
      "metadata": {
        "id": "O98ZbfVuPfAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######check_ans######\n",
        "\n",
        "data_train = pd.read_csv('/content/drive/MyDrive/dataset/train_onlySMILES.csv')\n",
        "lb=[]\n",
        "cnt=0\n",
        "for i in range(285):\n",
        "    lb.append(data_train.iloc[i].values[1])\n",
        "\n",
        "for i,j in zip(pre_train_res,lb):\n",
        "    print(f'{i} {j}')\n",
        "    if((i>0.8 and j==0) or (i<0.2 and j==1)):\n",
        "        cnt=cnt+1\n",
        "print(cnt)\n"
      ],
      "metadata": {
        "id": "ZMVfz46fOn5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "AN-hyG4iLdRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(\n",
        "    model,\n",
        "    show_shapes=False,\n",
        "    show_dtype=True,\n",
        "    show_layer_names=True,\n",
        "    rankdir=\"LR\",\n",
        "    expand_nested=True,\n",
        "    show_layer_activations=True,\n",
        "    show_trainable=False,\n",
        "    )"
      ],
      "metadata": {
        "id": "XOw02rIcLjr1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "WXN6Q4bgXNGI",
        "0i-T0uSqUg90",
        "s4Y-xzLZFfS4",
        "f2Z_1hdovrXb"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}